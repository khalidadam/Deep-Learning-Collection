{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fc548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "path = os.getcwd()\n",
    "train_data = torchvision.datasets.MNIST(path, download = True, train = True, transform = transforms.Compose([transforms.Pad(2), transforms.ToTensor()]))\n",
    "test_data = torchvision.datasets.MNIST(path, download = True, train = False, transform = transforms.Compose([transforms.Pad(2), transforms.ToTensor()]))\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [50000, 10000])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size = 16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size = 16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e500e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi = 100)\n",
    "for index in range(1, 3 * 5 + 1):\n",
    "    plt.subplot(3, 5, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(next(iter(train_loader))[0][index].reshape(32,32), cmap='gray')\n",
    "fig.suptitle('MNIST Dataset - preview');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbee25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3064, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.c1 = nn.Conv2d(in_channels = 1,out_channels = 6,kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.c2 = nn.Conv2d(in_channels = 6,out_channels = 16,kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.fc1 = nn.Linear(in_features = 16*5*5, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 84)\n",
    "        self.fc3 = nn.Linear(in_features = 84, out_features = 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.avg_pool2d(torch.tanh(self.c1(x)), kernel_size = 2, stride = 2, padding = 0)\n",
    "        x = F.avg_pool2d(torch.tanh(self.c2(x)), kernel_size = 2, stride = 2, padding = 0)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = F.log_softmax(x, dim = 1)\n",
    "        #x = torch.argmax(x, dim = 1)\n",
    "         \n",
    "        return x \n",
    "        \n",
    "leNet = LeNet()\n",
    "x = leNet(next(iter(train_loader))[0])\n",
    "l = nn.CrossEntropyLoss()\n",
    "l(x,next(iter(train_loader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fa368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self,dataset, val_loader, model, learning_rate = 1e-1):\n",
    "        self.dataset = dataset\n",
    "        self.val_loader = val_loader\n",
    "        self.model = model \n",
    "        self.lr = learning_rate\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.opt = torch.optim.SGD(self.model.parameters(), lr = self.lr)\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "    \n",
    "    def validation(self):\n",
    "        val_loss = 0\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                outputs = self.model(x)\n",
    "                loss = self.loss_function(outputs,y)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        return val_loss / len(val_loader)\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        for epoch in tqdm_notebook(range(epochs), desc = 'Epoch'):\n",
    "            batch_loss = 0\n",
    "            for inputs, targets in self.dataset:\n",
    "                self.opt.zero_grad()\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                loss = self.loss_function(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                batch_loss += loss.item()\n",
    "            self.train_loss.append(batch_loss / len(self.dataset))\n",
    "            self.val_loss.append(self.validation())\n",
    "    \n",
    "    def plot(self, save = False):\n",
    "        x = [i for i in range(len(self.train_loss))]\n",
    "        plt.figure(dpi=120)\n",
    "        plt.grid()\n",
    "        plt.plot(x, self.train_loss, color = 'b', label = 'Training')\n",
    "        plt.plot(x, self.val_loss, color = 'y', label = 'Validation')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend(loc = \"upper right\")\n",
    "        if save:\n",
    "            plt.savefig(path + \"/figures/Loss_figure.png\")\n",
    "\n",
    "        \n",
    "    def accuracy(self, test_loader):\n",
    "        acc = 0\n",
    "        for x, y in test_loader:\n",
    "            output = torch.argmax(F.log_softmax(self.model(x)), dim = 1)\n",
    "            acc += sum([1 for i in range(len(y)) if output[i] ==  y[i]]) / len(y)\n",
    "\n",
    "        print(\"Accuracy : {}\".format(acc/len(test_loader)))\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a1012e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85696243a26948418d939f7026460e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-16434f928a7a>:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = torch.argmax(F.log_softmax(self.model(x)), dim = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9869\n"
     ]
    }
   ],
   "source": [
    "n = network(train_loader, val_loader, LeNet())\n",
    "n.train(5)\n",
    "n.plot()\n",
    "n.accuracy(test_loader)\n",
    "n.plot(save = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
