{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nronoj1vvUaX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\" Convolution Block with Conv2d layer, Batch Normalization and ReLU. \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels : int,\n",
        "        out_channels : int,\n",
        "        kernel_size : int,\n",
        "        stride : int,\n",
        "        padding : int, \n",
        "        groups = 1,\n",
        "        bias=False,     \n",
        "        ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=bias)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.relu(self.bn(self.c(x)))\n",
        "\n",
        "class DepthwiseConvBlock(nn.Module):\n",
        "    \"\"\" Depthwise Separable Convolution Block. \"\"\" \n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels : int,\n",
        "        out_channels : int,\n",
        "        stride : int,\n",
        "        ):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.depthwise = ConvBlock(in_channels, in_channels, 3, stride, 1, in_channels)\n",
        "        self.pointwise = ConvBlock(in_channels, out_channels, 1, 1, 0)\n",
        "        \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    \"\"\" Baseline MobileNet model that takes in width(alpha)\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        alpha : float,\n",
        "        in_channels=3,\n",
        "        classes=1000\n",
        "        ):    \n",
        "\n",
        "        super().__init__()\n",
        "        \n",
        "        \"\"\" List of strides and channels for Depthwise Blocks \"\"\"\n",
        "        strides = [1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1]\n",
        "        channels = [32, 64, 128, 128, 256, 256, 512, 512, 512, 512, 512, 512, 1024, 1024]\n",
        "\n",
        "        if alpha < 1:\n",
        "            channels = [int(channel * alpha) for channel in channels]\n",
        "\n",
        "        \"\"\" List of Depthwise Blocks. \"\"\"\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        for i, stride in enumerate(strides):\n",
        "            self.blocks.append(DepthwiseConvBlock(channels[i], channels[i+1], stride))\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, channels[0], 3, 2, 1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(channels[-1], classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        \n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2FYEJJnsvYd_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Second hyperparameter is resolution multiplayer(rho). \"\"\"\n",
        "\"\"\" Baseline configuration is alpha=1, rho=1. \"\"\"\n",
        "\n",
        "rho = 1\n",
        "alpha = 1\n",
        "res = int(224 * rho)\n",
        "\n",
        "net = MobileNet(alpha)\n",
        "net(torch.rand(1, 3, res, res)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOnT_H712nV2",
        "outputId": "2eac28d8-a47e-4cac-874c-852eb6fd82a9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net, (3, res, res), 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1yl8r8R66Uv",
        "outputId": "36c585b2-2c1e-4122-d5a4-c2258cef1dda"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2          [1, 32, 112, 112]              64\n",
            "              ReLU-3          [1, 32, 112, 112]               0\n",
            "         ConvBlock-4          [1, 32, 112, 112]               0\n",
            "            Conv2d-5          [1, 32, 112, 112]             288\n",
            "       BatchNorm2d-6          [1, 32, 112, 112]              64\n",
            "              ReLU-7          [1, 32, 112, 112]               0\n",
            "         ConvBlock-8          [1, 32, 112, 112]               0\n",
            "            Conv2d-9          [1, 64, 112, 112]           2,048\n",
            "      BatchNorm2d-10          [1, 64, 112, 112]             128\n",
            "             ReLU-11          [1, 64, 112, 112]               0\n",
            "        ConvBlock-12          [1, 64, 112, 112]               0\n",
            "DepthwiseConvBlock-13          [1, 64, 112, 112]               0\n",
            "           Conv2d-14            [1, 64, 56, 56]             576\n",
            "      BatchNorm2d-15            [1, 64, 56, 56]             128\n",
            "             ReLU-16            [1, 64, 56, 56]               0\n",
            "        ConvBlock-17            [1, 64, 56, 56]               0\n",
            "           Conv2d-18           [1, 128, 56, 56]           8,192\n",
            "      BatchNorm2d-19           [1, 128, 56, 56]             256\n",
            "             ReLU-20           [1, 128, 56, 56]               0\n",
            "        ConvBlock-21           [1, 128, 56, 56]               0\n",
            "DepthwiseConvBlock-22           [1, 128, 56, 56]               0\n",
            "           Conv2d-23           [1, 128, 56, 56]           1,152\n",
            "      BatchNorm2d-24           [1, 128, 56, 56]             256\n",
            "             ReLU-25           [1, 128, 56, 56]               0\n",
            "        ConvBlock-26           [1, 128, 56, 56]               0\n",
            "           Conv2d-27           [1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [1, 128, 56, 56]             256\n",
            "             ReLU-29           [1, 128, 56, 56]               0\n",
            "        ConvBlock-30           [1, 128, 56, 56]               0\n",
            "DepthwiseConvBlock-31           [1, 128, 56, 56]               0\n",
            "           Conv2d-32           [1, 128, 28, 28]           1,152\n",
            "      BatchNorm2d-33           [1, 128, 28, 28]             256\n",
            "             ReLU-34           [1, 128, 28, 28]               0\n",
            "        ConvBlock-35           [1, 128, 28, 28]               0\n",
            "           Conv2d-36           [1, 256, 28, 28]          32,768\n",
            "      BatchNorm2d-37           [1, 256, 28, 28]             512\n",
            "             ReLU-38           [1, 256, 28, 28]               0\n",
            "        ConvBlock-39           [1, 256, 28, 28]               0\n",
            "DepthwiseConvBlock-40           [1, 256, 28, 28]               0\n",
            "           Conv2d-41           [1, 256, 28, 28]           2,304\n",
            "      BatchNorm2d-42           [1, 256, 28, 28]             512\n",
            "             ReLU-43           [1, 256, 28, 28]               0\n",
            "        ConvBlock-44           [1, 256, 28, 28]               0\n",
            "           Conv2d-45           [1, 256, 28, 28]          65,536\n",
            "      BatchNorm2d-46           [1, 256, 28, 28]             512\n",
            "             ReLU-47           [1, 256, 28, 28]               0\n",
            "        ConvBlock-48           [1, 256, 28, 28]               0\n",
            "DepthwiseConvBlock-49           [1, 256, 28, 28]               0\n",
            "           Conv2d-50           [1, 256, 14, 14]           2,304\n",
            "      BatchNorm2d-51           [1, 256, 14, 14]             512\n",
            "             ReLU-52           [1, 256, 14, 14]               0\n",
            "        ConvBlock-53           [1, 256, 14, 14]               0\n",
            "           Conv2d-54           [1, 512, 14, 14]         131,072\n",
            "      BatchNorm2d-55           [1, 512, 14, 14]           1,024\n",
            "             ReLU-56           [1, 512, 14, 14]               0\n",
            "        ConvBlock-57           [1, 512, 14, 14]               0\n",
            "DepthwiseConvBlock-58           [1, 512, 14, 14]               0\n",
            "           Conv2d-59           [1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-60           [1, 512, 14, 14]           1,024\n",
            "             ReLU-61           [1, 512, 14, 14]               0\n",
            "        ConvBlock-62           [1, 512, 14, 14]               0\n",
            "           Conv2d-63           [1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-64           [1, 512, 14, 14]           1,024\n",
            "             ReLU-65           [1, 512, 14, 14]               0\n",
            "        ConvBlock-66           [1, 512, 14, 14]               0\n",
            "DepthwiseConvBlock-67           [1, 512, 14, 14]               0\n",
            "           Conv2d-68           [1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-69           [1, 512, 14, 14]           1,024\n",
            "             ReLU-70           [1, 512, 14, 14]               0\n",
            "        ConvBlock-71           [1, 512, 14, 14]               0\n",
            "           Conv2d-72           [1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-73           [1, 512, 14, 14]           1,024\n",
            "             ReLU-74           [1, 512, 14, 14]               0\n",
            "        ConvBlock-75           [1, 512, 14, 14]               0\n",
            "DepthwiseConvBlock-76           [1, 512, 14, 14]               0\n",
            "           Conv2d-77           [1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-78           [1, 512, 14, 14]           1,024\n",
            "             ReLU-79           [1, 512, 14, 14]               0\n",
            "        ConvBlock-80           [1, 512, 14, 14]               0\n",
            "           Conv2d-81           [1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-82           [1, 512, 14, 14]           1,024\n",
            "             ReLU-83           [1, 512, 14, 14]               0\n",
            "        ConvBlock-84           [1, 512, 14, 14]               0\n",
            "DepthwiseConvBlock-85           [1, 512, 14, 14]               0\n",
            "           Conv2d-86           [1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-87           [1, 512, 14, 14]           1,024\n",
            "             ReLU-88           [1, 512, 14, 14]               0\n",
            "        ConvBlock-89           [1, 512, 14, 14]               0\n",
            "           Conv2d-90           [1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-91           [1, 512, 14, 14]           1,024\n",
            "             ReLU-92           [1, 512, 14, 14]               0\n",
            "        ConvBlock-93           [1, 512, 14, 14]               0\n",
            "DepthwiseConvBlock-94           [1, 512, 14, 14]               0\n",
            "           Conv2d-95           [1, 512, 14, 14]           4,608\n",
            "      BatchNorm2d-96           [1, 512, 14, 14]           1,024\n",
            "             ReLU-97           [1, 512, 14, 14]               0\n",
            "        ConvBlock-98           [1, 512, 14, 14]               0\n",
            "           Conv2d-99           [1, 512, 14, 14]         262,144\n",
            "     BatchNorm2d-100           [1, 512, 14, 14]           1,024\n",
            "            ReLU-101           [1, 512, 14, 14]               0\n",
            "       ConvBlock-102           [1, 512, 14, 14]               0\n",
            "DepthwiseConvBlock-103           [1, 512, 14, 14]               0\n",
            "          Conv2d-104             [1, 512, 7, 7]           4,608\n",
            "     BatchNorm2d-105             [1, 512, 7, 7]           1,024\n",
            "            ReLU-106             [1, 512, 7, 7]               0\n",
            "       ConvBlock-107             [1, 512, 7, 7]               0\n",
            "          Conv2d-108            [1, 1024, 7, 7]         524,288\n",
            "     BatchNorm2d-109            [1, 1024, 7, 7]           2,048\n",
            "            ReLU-110            [1, 1024, 7, 7]               0\n",
            "       ConvBlock-111            [1, 1024, 7, 7]               0\n",
            "DepthwiseConvBlock-112            [1, 1024, 7, 7]               0\n",
            "          Conv2d-113            [1, 1024, 4, 4]           9,216\n",
            "     BatchNorm2d-114            [1, 1024, 4, 4]           2,048\n",
            "            ReLU-115            [1, 1024, 4, 4]               0\n",
            "       ConvBlock-116            [1, 1024, 4, 4]               0\n",
            "          Conv2d-117            [1, 1024, 4, 4]       1,048,576\n",
            "     BatchNorm2d-118            [1, 1024, 4, 4]           2,048\n",
            "            ReLU-119            [1, 1024, 4, 4]               0\n",
            "       ConvBlock-120            [1, 1024, 4, 4]               0\n",
            "DepthwiseConvBlock-121            [1, 1024, 4, 4]               0\n",
            "AdaptiveAvgPool2d-122            [1, 1024, 1, 1]               0\n",
            "         Flatten-123                  [1, 1024]               0\n",
            "          Linear-124                  [1, 1000]       1,025,000\n",
            "================================================================\n",
            "Total params: 4,231,976\n",
            "Trainable params: 4,231,976\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 172.27\n",
            "Params size (MB): 16.14\n",
            "Estimated Total Size (MB): 188.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
