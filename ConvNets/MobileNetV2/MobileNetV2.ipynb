{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "Vj0FEebPcFgT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ek_CA8MzbvrR"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\" Convolution Block with Conv2d layer, Batch Normalization and ReLU. Act input defines whetver to apply activation or not. \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels : int,\n",
        "        out_channels : int,\n",
        "        kernel_size : int,\n",
        "        stride : int,\n",
        "        padding : int, \n",
        "        groups = 1,\n",
        "        act=True,\n",
        "        bias=False     \n",
        "        ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=bias)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        if act:\n",
        "            self.relu = nn.ReLU6()\n",
        "        else:\n",
        "            self.relu = nn.Identity()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.relu(self.bn(self.c(x)))\n",
        "\n",
        "class InvertedResBlock(nn.Module):\n",
        "    \"\"\" Inverted Residual Block with expansion(exp) parameter. \"\"\" \n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels : int,\n",
        "        out_channels : int,\n",
        "        stride : int,\n",
        "        exp : int\n",
        "        ):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.add = True if in_channels == out_channels and stride == 2 else False    \n",
        "        exp_channels = in_channels * exp\n",
        "\n",
        "        \"\"\" 3 Convolutions : Expansion, Depthwise, Pointwise. \"\"\"\n",
        "        self.expansion = ConvBlock(in_channels, exp_channels, 1, 1, 0, act=True)\n",
        "        self.dwise = ConvBlock(exp_channels, exp_channels, 3, stride, 1, groups=exp_channels)\n",
        "        self.pwise = ConvBlock(exp_channels, out_channels, 1, 1, 0, act=False)\n",
        "    \n",
        "        \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        res = x\n",
        "        x = self.expansion(x)\n",
        "        x = self.dwise(x)\n",
        "        x = self.pwise(x)\n",
        "        if self.add:\n",
        "            x = x + res\n",
        "\n",
        "        return x\n",
        "\n",
        "class MobileNetv2(nn.Module):\n",
        "    \"\"\" Baseline MobileNet model that takes in width(alpha)\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        alpha : float,\n",
        "        in_channels=3,\n",
        "        classes=1000\n",
        "        ):    \n",
        "\n",
        "        super().__init__()\n",
        "        \n",
        "        \"\"\" List of strides(s) and channels(c), expansion(t) for Inverted Residual Blocks and how many times they are repeated(n). \"\"\"\n",
        "        s = [1, 2, 2, 2, 1, 2, 1]\n",
        "        n = [1, 2, 3, 4, 3, 3, 1]\n",
        "        t = [1, 6, 6, 6, 6, 6, 6]\n",
        "        c = [32, 16, 24, 32, 64, 96, 160, 320, 1280]\n",
        "\n",
        "        if alpha > 1:\n",
        "            c = [int(channel * alpha) for channel in c]\n",
        "        \n",
        "        elif alpha < 1:\n",
        "            c = [int(channel * alpha) for channel in c[:-1]]\n",
        "\n",
        "        \"\"\" List of Inverted Residual Blocks. \"\"\"\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        for i in range(len(s)):\n",
        "            self._add_layer(c[i], c[i+1], s[i], n[i], t[i])\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, c[0], 3, 2, 1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(c[-2], c[-1], 1, 1, 0),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c[-1], classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "            print(x.shape)\n",
        "        \n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _add_layer(self, in_channels, out_channels, stride, n, t):\n",
        "        \"\"\" Add layer function which takes input and output channels, stride, repeats, expansion. \"\"\"\n",
        "        if n == 1:\n",
        "            self.blocks.append(InvertedResBlock(in_channels, out_channels, stride, t))\n",
        "        else:\n",
        "            self.blocks.append(InvertedResBlock(in_channels, in_channels, 1, t))\n",
        "            for _ in range(n-2):\n",
        "                self.blocks.append(InvertedResBlock(in_channels, in_channels, 1, t))\n",
        "\n",
        "            self.blocks.append(InvertedResBlock(in_channels, out_channels, stride, t))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Second hyperparameter is resolution multiplayer(rho). \"\"\"\n",
        "\"\"\" Baseline configuration is alpha=1, rho=1. \"\"\"\n",
        "\n",
        "rho = 1\n",
        "alpha = 1\n",
        "res = int(224 * rho)\n",
        "\n",
        "net = MobileNetv2(alpha)\n",
        "net(torch.rand(1, 3, res, res)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tAjoiCNgseI",
        "outputId": "48d3a8a6-407e-4bbb-cb55-fb346de8faef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 112, 112])\n",
            "torch.Size([1, 16, 112, 112])\n",
            "torch.Size([1, 24, 56, 56])\n",
            "torch.Size([1, 24, 56, 56])\n",
            "torch.Size([1, 24, 56, 56])\n",
            "torch.Size([1, 32, 28, 28])\n",
            "torch.Size([1, 32, 28, 28])\n",
            "torch.Size([1, 32, 28, 28])\n",
            "torch.Size([1, 32, 28, 28])\n",
            "torch.Size([1, 64, 14, 14])\n",
            "torch.Size([1, 64, 14, 14])\n",
            "torch.Size([1, 64, 14, 14])\n",
            "torch.Size([1, 96, 14, 14])\n",
            "torch.Size([1, 96, 14, 14])\n",
            "torch.Size([1, 96, 14, 14])\n",
            "torch.Size([1, 160, 7, 7])\n",
            "torch.Size([1, 320, 7, 7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}